<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tejoram Vivekanandan</title>
  
  <meta name="author" content="Tejoram Vivekanandan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-HCGNTLJKJ7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-HCGNTLJKJ7');
</script>
  
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tejoram Vivekanandan</name>
              </p>
              <p>
                I am the founder of a stealth startup in Seattle, building AI solutions. I hold a Master’s in Electrical Engineering and Data Science from the <a href="https://www.washington.edu/">University of Washington</a>.
              </p>
              <p>
                My experience includes roles as a Machine Learning Engineer at <a href="https://radius.ai/">Radius AI</a>, and Research Assistant positions at <a href="https://www.sciencehub.uw.edu/">UW’s Robotics Lab</a> and <a href="https://grail.cs.washington.edu/">GRAIL Lab</a>. I have also worked at IIT Madras’s <a href="http://www.ee.iitm.ac.in/comp_photolab/">Computational Imaging Lab</a>, NASA’s Jet Propulsion Laboratory (Juno mission), and the <a href="https://www.nrsc.gov.in/">Indian Space Research Organisation</a>.
              </p>
              <p>
                I hold a Bachelor’s in Electronics and Communication Engineering from the Coimbatore Institute of Technology. 
              </p>
              <p style="text-align:center">
                <a href="mailto:tejoramv1999@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://github.com/TejoramV">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/tejoram-vivekanandan/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="imgs/me.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="imgs/me-circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and image processing.
                Much of my research is about inferring the physical world (shape, motion, depth, color, light, etc) from images and videos. I also like to focus on interdisciplinary research, applying vision based methods to innovatively tackle problems in different fields. More recently, I have been working on multi-modal agents.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/7.png" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pathfinder-dx.github.io/">
                <papertitle>PathFinder: A Multi-Modal Multi-Agent System for Medical Diagnostic Decision-Making Applied to Histopathology</papertitle>
              </a>
              <br>

          	  <a href="https://fghezloo.github.io/">Fatemeh Ghezloo</a>, <a href="https://mehmetsayginseyfioglu.github.io/">Mehmet Saygin Seyfioglu</a>, <a href="https://www.linkedin.com/in/rustin-soraki/">Rustin Soraki</a>, <a href="https://wisdomikezogwo.github.io/">Wisdom O. Ikezogwo</a>, <a href="https://www.beibinli.com/">Beibin Li</a>, <strong>Tejoram Vivekanandan</strong>, <a href="https://profiles.ucla.edu/joann.elmore">Joann G. Elmore</a>, <a href="https://ranjaykrishna.com/index.html">Ranjay Krishna</a>, <a href="https://homes.cs.washington.edu/~shapiro/">Linda Shapiro</a>  <br>
	      [<a href="https://arxiv.org/abs/2502.08916">ICCV'25</a>]
              <br>
	   
              <p></p>
              <p>PathFinder addresses challenges in analyzing gigapixel-scale histopathology whole slide images (WSIs) through a multi-agent framework that emulates expert pathologists' diagnostic process. Unlike traditional AI approaches, PathFinder employs four specialized agents—Triage, Navigation, Description, and Diagnosis—that collaborate to analyze WSIs, identify relevant regions, and generate comprehensive diagnoses with natural language explanations. In skin melanoma diagnosis, PathFinder outperforms state-of-the-art methods by 8%, surpasses average pathologist performance by 9%, and provides inherent explainability through high-quality descriptive outputs comparable to GPT-4o.
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/5.jpeg" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Photo-realistic synthetic Image generation</papertitle>
              </a>
              <br>

          	  <strong>Tejoram Vivekanandan</strong>, <a href="https://theorg.com/org/radiusai/org-chart/daniel-king">Daniel King</a>, <a href="https://www.andreafanelli.info/">Andrea Fanelli</a> <br>
	      [<a href="data/Radius_AI.pdf">Project Report</a>]
              <br>
	   
              <p></p>
              <p>This project addresses Automatic Checkout challenges in retail by developing a synthetic image pipeline to enhance object detection training. Overcoming data scarcity from product seasonality and diverse variations, it employs advanced methods like GANs, NeRFs, and PixelNeRFs to generate realistic scenes. Integrating these images into YOLOv5 training boosts detection accuracy to a peak mAP-50 of 0.882 with a 4:6 real-to-synthetic ratio, demonstrating synthetic data augmentation as a scalable solution for robust retail environments.
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/1.png" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Correlation between color changes in Jupiter’s storm “Oval BA”, cloud
                  heights and ultraviolet exposure</papertitle>
              </a>
              <br>

          	  <strong>Tejoram Vivekanandan</strong>, <a href="https://science.jpl.nasa.gov/people/Orton/">Glenn Orton</a>, <a href="https://science.jpl.nasa.gov/people/momary/">Thomas Momary</a> <br>
	      [<a href="data/Color_changes_in_Jupiter’s_storm.pdf">Project Report</a>]
              <br>
	   
              <p></p>
              <p>To determine the correlation between the color change, the altitude and ultraviolet exposure of the storm’s particles, near-infrared images of Jupiter with Oval BA present were examined. After calibration and preprocessing the images during red, white and the transition phase were compiled for different wavelengths. The reflectivity of the vortex at each wavelength was adjusted subject to angles of emission and incident sunlight using the Minnaert function. Results confirmed a change in altitude of particles between the red and white epochs.
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/2.png" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Shadow Detection and Radiometric Restoration in VHR Satellite Imagery</papertitle>
              </a>
              <br>

          	  <strong>Tejoram Vivekanandan</strong>, <a href="https://www.researchgate.net/profile/Venkateswarlu-Ernala">E.Venkateswarlu</a>, <a href="https://www.researchgate.net/profile/Thara-Nair">Thara Nair</a>, <a href="https://www.researchgate.net/profile/Vinod-Bothale-2">Vinod M Bothale</a>  <br>
	      [<a href="data/Shadow_detection_and_Radiometric_Restoration_in_VHR_satellite_imagery.pdf">Project Report</a>]
              <br>
	   
              <p></p>
              <p>Shadow restoration approach for high resolution satellite images was adopted. This approach detected the shadow area and segmented the image into regions relevant to the types of land surface. Thereafter, shadow restoration was applied region-wise in relation to the degree of correspondence between shadow and neighboring non-shadow regions. The results proved that the shadow regions processed had a better appearance and were highly compatible with surrounding non-shadow regions. Thus, the final accuracy was more than that of the conventional approaches. 
              </p>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/3.png" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Autonomous vehicle using Artificial Intelligence</papertitle>
              </a>
              <br>

          	  <strong>Tejoram Vivekanandan</strong>, <a href="">Jenisha Priscilla.J</a>, <a href="">Swetha</a>,<a href="https://www.cit.edu.in/staff/ms-b-bhuvaneshwariece/">B.Bhuvaneshwari</a>, <a href="https://www.cit.edu.in/staff/ms-s-dhanalakshmiece/">Dhanalakshmi.S</a>  <br>
	      [<a href="data/Autonomous_vehicle_using_Artificial_Intelligence.pdf">Project Report</a>]
              <br>
	   
              <p></p>
	      <p>A prototype of an intelligent self-driving vehicle was developed on a Raspberry Pi with a variety of machine learning algorithms. It was able to predict the direction and control the vehicle based on the predictions. The prototype was trained to recognize traffic signs and to navigate without collision. For this purpose, the images of a track collected from a Pi camera were used to train different models of neural networks and the performance of each model was tested. Haar cascade classifier based stop sign detection signals were used to stop the vehicle. 95% decision accuracy was attained using softmax activation function with 256 hidden layer nodes.
              </p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="imgs/4.png" alt="Image Unavailable" width="260" height="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Handwritten Digit Recognition</papertitle>
              </a>
              <br>

          	  <strong>Tejoram Vivekanandan</strong><br>
	      [<a href="https://github.com/TejoramV/Handwritten-Digit-Recognition">Github Link</a>]
              <br>
	   
              <p></p>
	      <p>In this project, handwritten numerics from a live video input was recognized and matched with telephone directory to find the name associated with the detected telephone number. Image background was removed through edge detection, localization and perspective transform. After Thresholding, ROI bounding boxes were computed. Finally digits were recognized by deep neural network through classification. 
              </p>
            </td>
          </tr> 
          

        </tbody></table>

        <!-- ========================================================================================================================================= -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Updates</heading>
            </td>
          </tr>
        </tbody></table>
        <table border=0 class="bg_colour" style="padding-left:20px down: 10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr>
          <td class="tdNews"><p style="color:purple; display:inline">Sep '22</p></td>
         <td>
          I am excited to join the <a href="https://www.washington.edu/">University of Washington</a> for my grad school.
          </td>
      </tr>
      <tr>
          <td class="tdNews"><p style="color:purple; display:inline">Sep '21</p></td>
         <td>
          I am joining the <a href="http://www.ee.iitm.ac.in/comp_photolab/">Computational Imaging Lab</a> of Indian Institute of Technology, Madras. I'll be working with <a href="http://www.ee.iitm.ac.in/kmitra/">Dr. Kaushik Mitra</a>.
          </td>
      </tr>          
     <tr>
        <td class="tdNews"><p style="color:purple; display:inline">Jan '21</p></td>
      <td>
        Shadow Detection and Restoration in VHR Satellite Imagery got accepted for peer review in Journal of the Indian Society of Remote Sensing. 
      </td>
    </tr>

     <tr>
        <td class="tdNews"><p style="color:purple; display:inline">Aug '20</p></td>
      <td>
        Super excited to be selected for the JPL Visiting Student Research Program. I'll be working with <a href="https://science.jpl.nasa.gov/people/Orton/"> Dr. Glenn Orton </a> at the Planetary and Exoplanetary Systems Department at <a href="https://www.jpl.nasa.gov/">NASA Jet Propulsion Laboratory</a> from September. 
      </td>
    </tr>

     
    <tr>
        <td class="tdNews"><p style="color:purple; display:inline">Nov '19</p></td>
      <td>
        I'll be starting my internship with Ms. Thara Nair at 
        <a href="https://www.nrsc.gov.in/">Indian Space Research Organisation, Hyderabad</a>.
      </td>
    </tr>

 <!-- ===============================================================================================================================================-->

<br>

     <table border=0 class="bg_colour" style="width:100%;border:0px;border-spacing:25px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
       <tr style="padding:20px">
          <td class="tdLogo">
            <img class="logo" src="imgs/W.png">
          </td>
          <td class="tdLogo">
            <img class="logo" src="imgs/CIT.png">
          </td>
         <td class="tdLogo">
           <img class="logo" src="imgs/isro.png">
         </td>
         <td class="tdLogo">
           <img class="logo" src="imgs/nasajpl.png">
         </td>
         <td class="tdLogo">
          <img class="logo" src="imgs/iitm.png">
        </td>

<table border=0 style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
         
       </tbody>
       </td>
     </tr>
   </table>


</body>

</html>
